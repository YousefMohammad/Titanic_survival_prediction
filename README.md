# *Titanic Survival Prediction*

# Overview

The sinking of the Titanic is one of the most infamous shipwrecks in history.

On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.

While some element of luck was involved in surviving, some groups were more likely to survive than others.

<hr/>

The Model Predicting Whether the passenger on the Titanic ship will survive or not using different classification Models, 
Visualization and report will explain the model performance and accuracy

<hr/>

# Idea behind The NoteBook

The key to solving this problem is preprocessing and feature engineering to add or split new features from old ones.

On another hand, all features are necessary for developing your model.

the model is supported by hyper-parameter tuning and cross-validation to improve the model's accuracy and make it more reliable

also, exploratory analysis is important for knowing data more and more

<hr/>

# Technology used
  
  - xgboost
  - scikit-learn

# Top Models used

   - Random Forest
   - Extreme Gradient Boosting
   - Decision Tree Model 

# The Public score after trying several submissions on Kaggle:

* The public score of **Random Forest Model = 0.80622**
* The public score of **Extreme Gradient Boosting Model = 0.80622**
* The public score of the Decision Tree Model = 0.79168


* The public score of Voting with 3 selected models = 0.79425
* The public score of Voting with 5 selected models = 0.78947
* The public score of Voting with the selected ALL model = 0.78468

## **The public score in Kaggle is the higher one which is 0.80622** 

  

  
